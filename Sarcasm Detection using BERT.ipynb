{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39daf497",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df7cb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf33e05",
   "metadata": {},
   "source": [
    "# Loading the Sarcasm Dataset\n",
    "## Datset Link:- https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5db4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "data_2 = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "data =  pd.concat([data_1, data_2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3b696",
   "metadata": {},
   "source": [
    "# Train Test Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616f7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['headline'],data['is_sarcastic'], stratify=data['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bc0ed",
   "metadata": {},
   "source": [
    "# Loading BERT Preprocess & Base Model from Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a9ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c278758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_word_ids', 'input_type_ids', 'input_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = ['Very bad movie','I love Python']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc67926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3c06fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_outputs', 'default', 'sequence_output', 'pooled_output'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "bert_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660b7fe",
   "metadata": {},
   "source": [
    "## BERT(base) Encodes any sentence into an array of 768 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91705272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['pooled_output'].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04bc25",
   "metadata": {},
   "source": [
    "## A look at Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e6008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26170    retirement overseas: are we all just waiting f...\n",
       "22909    moron stepfather takes care of child who doesn...\n",
       "2040                 parking-ramp attendant moves slightly\n",
       "25043    federal judge pencils blocking trump's unconst...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcf0b5",
   "metadata": {},
   "source": [
    "# Craeting a function for Embedding the Sentence & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ca9ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.8435168 , -0.5132728 , -0.8884576 , ..., -0.747489  ,\n",
       "        -0.7531474 ,  0.91964483],\n",
       "       [-0.87208354, -0.50543964, -0.94446677, ..., -0.858475  ,\n",
       "        -0.71745336,  0.88082975]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embedding(sentences):\n",
    "    text_preprocessed = bert_preprocess_model(sentences)\n",
    "    embedding = bert_model(text_preprocessed)\n",
    "    return embedding['pooled_output']\n",
    "        \n",
    "        \n",
    "get_sentence_embedding([\n",
    "    \"500$ discount. hurry up\", \n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca61b38a",
   "metadata": {},
   "source": [
    "# Creating the Main Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142a5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'input_word_ids': ( 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      {'encoder_outputs':  109482241   keras_layer[0][0]                \n",
      "                                                                 keras_layer[0][1]                \n",
      "                                                                 keras_layer[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           keras_layer_1[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          76900       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            101         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,559,242\n",
      "Trainable params: 77,001\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Bert Layers\n",
    "text_input = Input(shape=(),dtype=tf.string,name='text')\n",
    "preprocessed_text = bert_preprocess_model(text_input) \n",
    "outputs = bert_model(preprocessed_text)\n",
    "\n",
    "#Neural Network Layers\n",
    "l = Dropout(0.1)(outputs['pooled_output'])\n",
    "l = Dense(100,activation='relu')(l)\n",
    "l = Dense(1,activation='sigmoid')(l)\n",
    "\n",
    "model = Model(inputs=[text_input],outputs=[l])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8456a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1292a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"Sarcasm+BERT.h5\", \n",
    "                             monitor='loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a2f793d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13832,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d69ed5",
   "metadata": {},
   "source": [
    "# Fitting the Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a3e1e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 207s 160ms/step - loss: 0.4477 - accuracy: 0.7883\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.44768, saving model to Sarcasm+BERT.h5\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 207s 160ms/step - loss: 0.4367 - accuracy: 0.7900\n",
      "\n",
      "Epoch 00002: loss improved from 0.44768 to 0.43669, saving model to Sarcasm+BERT.h5\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 202s 156ms/step - loss: 0.4353 - accuracy: 0.7910\n",
      "\n",
      "Epoch 00003: loss improved from 0.43669 to 0.43529, saving model to Sarcasm+BERT.h5\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 206s 159ms/step - loss: 0.4248 - accuracy: 0.7976\n",
      "\n",
      "Epoch 00004: loss improved from 0.43529 to 0.42484, saving model to Sarcasm+BERT.h5\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 207s 160ms/step - loss: 0.4224 - accuracy: 0.7995\n",
      "\n",
      "Epoch 00005: loss improved from 0.42484 to 0.42243, saving model to Sarcasm+BERT.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4281b9898>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "090628b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 67s 154ms/step - loss: 0.4078 - accuracy: 0.8027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4077775478363037, 0.802703857421875]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83e5ee",
   "metadata": {},
   "source": [
    "# Now making some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66a9a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sarcasm(sentence):\n",
    "    pred = model.predict([sentence])\n",
    "    pred = pred[0][0]*100\n",
    "    if pred>=50: return \"It's a sarcasm!\" \n",
    "    else: return \"It's not a sarcasm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0058c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's not a sarcasm.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I was depressed. He asked me to be happy. I am not depressed anymore.\"\n",
    "predict_sarcasm(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9300a0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's not a sarcasm.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"You just broke my car window. Great job.\"\n",
    "predict_sarcasm(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acbcb4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's not a sarcasm.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"You just saved my dog's life. Thanks a million.\"\n",
    "predict_sarcasm(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
